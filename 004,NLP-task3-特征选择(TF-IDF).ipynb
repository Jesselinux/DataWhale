{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'the', 'first', 'document'], ['this', 'is', 'the', 'second', 'second', 'document'], ['and', 'the', 'third', 'one'], ['is', 'this', 'the', 'first', 'document']]\n"
     ]
    }
   ],
   "source": [
    "# 1,gensim计算tf-idf:\n",
    "corpus = [\n",
    "    'this is the first document',\n",
    "    'this is the second second document',\n",
    "    'and the third one',\n",
    "    'is this the first document'\n",
    "]\n",
    "\n",
    "word_list = []\n",
    "for i in range(len(corpus)):\n",
    "    word_list.append(corpus[i].split(' '))\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)], [(0, 1), (2, 1), (3, 1), (4, 1), (5, 2)], [(3, 1), (6, 1), (7, 1), (8, 1)], [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)]] \n",
      "***\n",
      "{'document': 0, 'first': 1, 'is': 2, 'the': 3, 'this': 4, 'second': 5, 'and': 6, 'one': 7, 'third': 8}\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "# 赋给语料库中每个词(不重复的词)一个整数id\n",
    "dictionary = corpora.Dictionary(word_list)\n",
    "new_corpus = [dictionary.doc2bow(text) for text in word_list]\n",
    "print(new_corpus,'\\n***')      # 元组中第一个元素是词语在词典中对应的id，第二个元素是词语在文档中出现的次数\n",
    "\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 0.33699829595119235), (1, 0.8119707171924228), (2, 0.33699829595119235), (4, 0.33699829595119235)], [(0, 0.10212329019650272), (2, 0.10212329019650272), (4, 0.10212329019650272), (5, 0.9842319344536239)], [(6, 0.5773502691896258), (7, 0.5773502691896258), (8, 0.5773502691896258)], [(0, 0.33699829595119235), (1, 0.8119707171924228), (2, 0.33699829595119235), (4, 0.33699829595119235)]]\n"
     ]
    }
   ],
   "source": [
    "# 训练模型并保存\n",
    "from gensim import models\n",
    "tfidf = models.TfidfModel(new_corpus)\n",
    "tfidf.save(\"../OutPut/my_model.tfidf\")\n",
    "\n",
    "# 载入模型\n",
    "tfidf = models.TfidfModel.load(\"../OutPut/my_model.tfidf\")\n",
    "\n",
    "# 使用这个训练好的模型得到单词的tf-idf值:\n",
    "'''gensim训练出来的tf-idf值左边是词的id，右边是词的tfidf值; gensim有自动去除停用词的功能，比如the;\n",
    "gensim会自动去除单个字母，比如i; gensim会去除没有被训练到的词，比如name; 所以通过gensim并不能计算每个单词的tfidf值'''\n",
    "\n",
    "tfidf_vec = []\n",
    "for i in range(len(corpus)):\n",
    "    string = corpus[i]\n",
    "    string_bow = dictionary.doc2bow(string.lower().split())\n",
    "    string_tfidf = tfidf[string_bow]\n",
    "    tfidf_vec.append(string_tfidf)\n",
    "print(tfidf_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "{'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}\n",
      "[[0.         0.43877674 0.54197657 0.43877674 0.         0.\n",
      "  0.35872874 0.         0.43877674]\n",
      " [0.         0.27230147 0.         0.27230147 0.         0.85322574\n",
      "  0.22262429 0.         0.27230147]\n",
      " [0.55280532 0.         0.         0.         0.55280532 0.\n",
      "  0.28847675 0.55280532 0.        ]\n",
      " [0.         0.43877674 0.54197657 0.43877674 0.         0.\n",
      "  0.35872874 0.         0.43877674]]\n"
     ]
    }
   ],
   "source": [
    "# 2,sklearn库计算tf-idf:\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vec.fit_transform(corpus)\n",
    "\n",
    "# 得到语料库所有不重复的词\n",
    "print(tfidf_vec.get_feature_names())\n",
    "\n",
    "# 得到每个单词对应的id值\n",
    "print(tfidf_vec.vocabulary_)\n",
    "\n",
    "# 得到每个句子所对应的向量\n",
    "# 向量里数字的顺序是按照词语的id顺序来的\n",
    "print(tfidf_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'the', 'first', 'document'], ['this', 'is', 'the', 'second', 'second', 'document'], ['and', 'the', 'third', 'one'], ['is', 'this', 'the', 'first', 'document']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Counter({'this': 1, 'is': 1, 'the': 1, 'first': 1, 'document': 1}),\n",
       " Counter({'this': 1, 'is': 1, 'the': 1, 'second': 2, 'document': 1}),\n",
       " Counter({'and': 1, 'the': 1, 'third': 1, 'one': 1}),\n",
       " Counter({'is': 1, 'this': 1, 'the': 1, 'first': 1, 'document': 1})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3，python计算tf-idf：\n",
    "from collections import Counter\n",
    "word_list = []\n",
    "for i in range(len(corpus)):\n",
    "    word_list.append(corpus[i].split(' '))\n",
    "print(word_list)\n",
    "\n",
    "countlist = []  # 计算词频\n",
    "for i in range(len(word_list)):\n",
    "    count = Counter(word_list[i])\n",
    "    countlist.append(count)\n",
    "countlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(word, count):\n",
    "    return count[word] / sum(count.values())  # count[word]可以得到每个单词的词频， sum(count.values())得到整个句子的单词总数\n",
    "\n",
    "def n_containing(word, count_list):\n",
    "    return sum(1 for count in count_list if word in count)  # 统计含有该单词的句子数\n",
    " \n",
    "def idf(word, count_list):\n",
    "    return math.log(len(count_list) / (1 + n_containing(word, count_list)))  # len(count_list)是指句子的总数，n_containing(word, count_list)是指含有该单词的句子的总数，加1是为了防止分母为0\n",
    "\n",
    "def tfidf(word, count, count_list):\n",
    "    return tf(word, count) * idf(word, count_list)  # 将tf和idf相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in document 1\n",
      "\tWord: first, TF-IDF: 0.05754\n",
      "\tWord: this, TF-IDF: 0.0\n",
      "\tWord: is, TF-IDF: 0.0\n",
      "\tWord: document, TF-IDF: 0.0\n",
      "\tWord: the, TF-IDF: -0.04463\n",
      "Top words in document 2\n",
      "\tWord: second, TF-IDF: 0.23105\n",
      "\tWord: this, TF-IDF: 0.0\n",
      "\tWord: is, TF-IDF: 0.0\n",
      "\tWord: document, TF-IDF: 0.0\n",
      "\tWord: the, TF-IDF: -0.03719\n",
      "Top words in document 3\n",
      "\tWord: and, TF-IDF: 0.17329\n",
      "\tWord: third, TF-IDF: 0.17329\n",
      "\tWord: one, TF-IDF: 0.17329\n",
      "\tWord: the, TF-IDF: -0.05579\n",
      "Top words in document 4\n",
      "\tWord: first, TF-IDF: 0.05754\n",
      "\tWord: is, TF-IDF: 0.0\n",
      "\tWord: this, TF-IDF: 0.0\n",
      "\tWord: document, TF-IDF: 0.0\n",
      "\tWord: the, TF-IDF: -0.04463\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "for i, count in enumerate(countlist):\n",
    "    print(\"Top words in document {}\".format(i + 1))\n",
    "    scores = {word: tfidf(word, count, countlist) for word in count}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
