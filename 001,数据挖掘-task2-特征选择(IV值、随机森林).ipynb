{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 7\n",
      "(4754, 90)\n",
      "44 90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>缺失百分比</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [缺失百分比]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0，task1-缺省值处理：\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection  import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv('../DataSets/001data.csv', encoding='gbk')\n",
    "\n",
    "columns_dropna = ['bank_card_no', 'reg_preference_for_trad', 'id_name','first_transaction_time','trade_no',\n",
    "                 'latest_query_time','loans_latest_time']  # 对于这些列实行删除NA样本的操作\n",
    "temp_columns = list(data.columns.values)\n",
    "columns_imputer = []                                       # 对于剩余的列实行填充0值的操作\n",
    "for i in range(len(temp_columns)):\n",
    "    if temp_columns[i] not in columns_dropna:\n",
    "        columns_imputer.append(temp_columns[i])\n",
    "print(len(columns_imputer), len(columns_dropna))\n",
    "\n",
    "print(data.shape)\n",
    "data.dropna(axis=0, how='any', subset=columns_dropna, inplace=True)         # 删除缺省值样本\n",
    "data = data.replace(np.NaN, 0)                                              # 缺省值填充0\n",
    "\n",
    "column_headers = list(data.columns.values)\n",
    "print(column_headers.index('status'), len(column_headers))\n",
    "\n",
    "\n",
    "# 删掉id数据：\n",
    "columns_drop = ['bank_card_no','source','id_name','unnameid','custid','student_feature','trade_no']\n",
    "data.drop(columns_drop, axis=1, inplace=True)\n",
    "# 日期数据格式化：\n",
    "data['latest_query_time'] = pd.to_datetime(data['latest_query_time'])\n",
    "data['loans_latest_time'] = pd.to_datetime(data['loans_latest_time'])\n",
    "# 将城市特征数值化：\n",
    "map_dic = {'一线城市':'1','二线城市':'2','三线城市':'3','境外':'4','其他':'0'}\n",
    "data['reg_preference_for_trad'] = data['reg_preference_for_trad'].map(map_dic)\n",
    "# 将时间戳数据列丢掉：\n",
    "data.drop(['latest_query_time','loans_latest_time'], axis=1, inplace=True)\n",
    "# 丢掉方差为零的列：\n",
    "data.drop(data.columns[data.std()==0], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "data.drop(['reg_preference_for_trad'], axis=1, inplace=True)  # 为什么'reg_preference_for_trad'的缺失率会是100%\n",
    "# 统计缺失值占比：\n",
    "data_missing = (data.isnull().sum()/len(data))*100    # np.isnan(data):可将他替换成 data.isnull()\n",
    "data_missing = data_missing.drop(data_missing[data_missing==0].index).sort_values(ascending=False)\n",
    "miss_data = pd.DataFrame({'缺失百分比':data_missing})\n",
    "miss_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) low_volume_percent             0.051434\n",
      " 2) middle_volume_percent          0.040662\n",
      " 3) take_amount_in_later_12_month_highest 0.037493\n",
      " 4) trans_amount_increase_rate_lately 0.031835\n",
      " 5) trans_activity_month           0.030872\n",
      " 6) trans_activity_day             0.027339\n",
      " 7) transd_mcc                     0.021421\n",
      " 8) trans_days_interval_filter     0.019528\n",
      " 9) trans_days_interval            0.018560\n",
      "10) regional_mobility              0.017795\n",
      "11) repayment_capability           0.017736\n",
      "12) is_high_user                   0.017366\n",
      "13) number_of_trans_from_2011      0.017050\n",
      "14) first_transaction_time         0.016615\n",
      "15) historical_trans_amount        0.015945\n",
      "16) historical_trans_day           0.015517\n",
      "17) rank_trad_1_month              0.015122\n",
      "18) trans_amount_3_month           0.014880\n",
      "19) avg_consume_less_12_valid_month 0.014417\n",
      "20) abs                            0.014322\n",
      "21) top_trans_count_last_1_month   0.014062\n",
      "22) avg_price_last_12_month        0.014060\n",
      "23) avg_price_top_last_12_valid_month 0.014008\n",
      "24) trans_top_time_last_1_month    0.013745\n",
      "25) trans_top_time_last_6_month    0.013684\n",
      "26) consume_top_time_last_1_month  0.013494\n",
      "27) consume_top_time_last_6_month  0.012713\n",
      "28) cross_consume_count_last_1_month 0.012507\n",
      "29) trans_fail_top_count_enum_last_1_month 0.012282\n",
      "30) trans_fail_top_count_enum_last_6_month 0.011880\n",
      "31) trans_fail_top_count_enum_last_12_month 0.011804\n",
      "32) consume_mini_time_last_1_month 0.011642\n",
      "33) max_cumulative_consume_later_1_month 0.011571\n",
      "34) max_consume_count_later_6_month 0.011533\n",
      "35) railway_consume_count_last_12_month 0.011060\n",
      "36) pawns_auctions_trusts_consume_last_1_month 0.010997\n",
      "37) pawns_auctions_trusts_consume_last_6_month 0.010779\n",
      "38) jewelry_consume_count_last_6_month 0.010750\n",
      "39) first_transaction_day          0.010701\n",
      "40) trans_day_last_12_month        0.010556\n",
      "41) apply_score                    0.010533\n",
      "42) apply_credibility              0.010453\n",
      "43) query_org_count                0.010259\n",
      "44) query_finance_count            0.010218\n",
      "45) query_cash_count               0.010078\n",
      "46) query_sum_count                0.009893\n",
      "47) latest_one_month_apply         0.009890\n",
      "48) latest_three_month_apply       0.009868\n",
      "49) latest_six_month_apply         0.009841\n",
      "50) loans_score                    0.009650\n",
      "51) loans_credibility_behavior     0.009519\n",
      "52) loans_count                    0.009513\n",
      "53) loans_settle_count             0.009411\n",
      "54) loans_overdue_count            0.009234\n",
      "55) loans_org_count_behavior       0.009082\n",
      "56) consfin_org_count_behavior     0.009036\n",
      "57) loans_cash_count               0.008719\n",
      "58) latest_one_month_loan          0.008685\n",
      "59) latest_three_month_loan        0.008248\n",
      "60) latest_six_month_loan          0.008174\n",
      "61) history_suc_fee                0.008167\n",
      "62) history_fail_fee               0.007967\n",
      "63) latest_one_month_suc           0.007746\n",
      "64) latest_one_month_fail          0.007694\n",
      "65) loans_long_time                0.007659\n",
      "66) loans_credit_limit             0.007627\n",
      "67) loans_credibility_limit        0.007590\n",
      "68) loans_org_count_current        0.007399\n",
      "69) loans_product_count            0.007313\n",
      "70) loans_max_limit                0.007264\n",
      "71) loans_avg_limit                0.007221\n",
      "72) consfin_credit_limit           0.006544\n",
      "73) consfin_credibility            0.005689\n",
      "74) consfin_org_count_current      0.005332\n",
      "75) consfin_product_count          0.004084\n",
      "76) consfin_max_limit              0.003526\n",
      "77) consfin_avg_limit              0.000790\n",
      "78) latest_query_day               0.000227\n",
      "79) loans_latest_day               0.000117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jesse/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 2，使用随机会森林进行特征选择：\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "x_columns = []  # X的列属性(x变量)\n",
    "for i in range(len(column_headers)):\n",
    "    if column_headers[i] not in ['reg_preference_for_trad','latest_query_time','loans_latest_time','status','bank_card_no','source','id_name','unnameid','custid','student_feature','trade_no']:\n",
    "        x_columns.append(column_headers[i])  \n",
    "        \n",
    "X = data[x_columns]  # 获取x变量\n",
    "Y = data['status']   # 获取y标签(label)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X, Y)\n",
    "\n",
    "importance = clf.feature_importances_\n",
    "indices = np.argsort(importance)[::-1]\n",
    "features = X.columns\n",
    "for f in range(X.shape[1]):\n",
    " print((\"%2d) %-*s %f\" % (f + 1, 30, features[f], importance[indices[f]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jesse/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:31: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unnameid： 0.0\n",
      "custid： 0.0\n",
      "trade_no： 0.0\n",
      "bank_card_no： 0.0\n",
      "low_volume_percent： 0.03434912946670754\n",
      "middle_volume_percent： 0.07118473287723781\n",
      "take_amount_in_later_12_month_highest： 0.08329868129431747\n",
      "trans_amount_increase_rate_lately： 0.2883857251682308\n",
      "trans_activity_month： 0.0728243237636469\n",
      "trans_activity_day： 0.36466249883484175\n",
      "transd_mcc： 0.03615978377155986\n",
      "trans_days_interval： 0.09452853184236024\n",
      "regional_mobility： 0.007908925668911125\n",
      "student_feature： 0.0009555051797128911\n",
      "repayment_capability： 0.4390959671989395\n",
      "is_high_user： 0.005613886645064013\n",
      "number_of_trans_from_2011： 0.057930909034620885\n",
      "first_transaction_time： 0.4861222320898152\n",
      "historical_trans_amount： 0.053932681011240866\n",
      "historical_trans_day： 0.3525315105292556\n",
      "rank_trad_1_month： 0.12800012489827373\n",
      "trans_amount_3_month： 0.24484789224813222\n",
      "avg_consume_less_12_valid_month： 0.01366176736863671\n",
      "abs： 0.3727207019325916\n",
      "top_trans_count_last_1_month： 0.07238437681409188\n",
      "avg_price_last_12_month： 0.19973803729124645\n",
      "avg_price_top_last_12_valid_month： 0.0448799551161269\n",
      "reg_preference_for_trad： 0.002088719638380976\n",
      "trans_top_time_last_1_month： 0.10181052061837485\n",
      "trans_top_time_last_6_month： 0.06783759655355802\n",
      "consume_top_time_last_1_month： 0.09524841540395028\n",
      "consume_top_time_last_6_month： 0.07432209918398235\n",
      "cross_consume_count_last_1_month： 0.013730867661866968\n",
      "trans_fail_top_count_enum_last_1_month： 0.5945548896319728\n",
      "trans_fail_top_count_enum_last_6_month： 0.2783577754538106\n",
      "trans_fail_top_count_enum_last_12_month： 0.2649286825335892\n",
      "consume_mini_time_last_1_month： 0.0899281620326396\n",
      "max_cumulative_consume_later_1_month： 0.3956491245615908\n",
      "max_consume_count_later_6_month： 0.03062688466670764\n",
      "railway_consume_count_last_12_month： 0.006307128262682564\n",
      "pawns_auctions_trusts_consume_last_1_month： 0.19699501522871354\n",
      "pawns_auctions_trusts_consume_last_6_month： 0.3389607214125947\n",
      "jewelry_consume_count_last_6_month： 0.0019510185472895417\n",
      "status： 0.0\n",
      "source： 0.0\n",
      "first_transaction_day： 0.4861222320898152\n",
      "trans_day_last_12_month： 0.1693760273268455\n",
      "id_name： 0.005175703316495677\n",
      "apply_score： 0.4918946855152253\n",
      "apply_credibility： 0.0407016198526198\n",
      "query_org_count： 0.028526967528461396\n",
      "query_finance_count： 0.01883760825079841\n",
      "query_cash_count： 0.03182175138557366\n",
      "query_sum_count： 0.0564050770802192\n",
      "latest_query_time： 0.19480522664248806\n",
      "latest_one_month_apply： 0.051393502672567204\n",
      "latest_three_month_apply： 0.049732356675958926\n",
      "latest_six_month_apply： 0.039731457198607247\n",
      "loans_score： 0.6214925431726865\n",
      "loans_credibility_behavior： 0.015147189770975388\n",
      "loans_count： 0.13654747372185833\n",
      "loans_settle_count： 0.07975696874387915\n",
      "loans_overdue_count： 0.3923359913425925\n",
      "loans_org_count_behavior： 0.03235501235370871\n",
      "consfin_org_count_behavior： 0.024380821724102025\n",
      "loans_cash_count： 0.02974705927366485\n",
      "latest_one_month_loan： 0.016360656963708916\n",
      "latest_three_month_loan： 0.04463582457502856\n",
      "latest_six_month_loan： 0.07556114729031406\n",
      "history_suc_fee： 0.1295224405045246\n",
      "history_fail_fee： 0.5133547604785954\n",
      "latest_one_month_suc： 0.1505871178724152\n",
      "latest_one_month_fail： 0.25593109317817125\n",
      "loans_long_time： 0.10917949026234713\n",
      "loans_latest_time： 0.18055372690968458\n",
      "loans_credit_limit： 0.036173068257932414\n",
      "loans_credibility_limit： 0.023876694793468937\n",
      "loans_org_count_current： 0.02974705927366485\n",
      "loans_product_count： 0.030767681943107732\n",
      "loans_max_limit： 0.0810045117961755\n",
      "loans_avg_limit： 0.3522987684188826\n",
      "consfin_credit_limit： 0.2147374492843147\n",
      "consfin_credibility： 0.028108692856604525\n",
      "consfin_org_count_current： 0.024380821724102025\n",
      "consfin_product_count： 0.02591024563815903\n",
      "consfin_max_limit： 0.11093025966669148\n",
      "consfin_avg_limit： 0.2751209316677875\n",
      "latest_query_day： 0.14175486373224241\n",
      "loans_latest_day： 0.1771739565352234\n"
     ]
    }
   ],
   "source": [
    "# 1，使用iv值进行特征选择：\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calc_iv(df, feature, target, pr=False):\n",
    "    \"\"\"\n",
    "    Set pr=True to enable printing of output.\n",
    "\n",
    "    Output:\n",
    "      * iv: float,\n",
    "      * data: pandas.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    lst = []\n",
    "    df[feature] = df[feature].fillna('NULL')\n",
    "\n",
    "    for i in range(df[feature].nunique()):  # nuinque()是查看该序列(axis=0/1对应着列或行)的不同值的数量个数\n",
    "        val = list(df[feature].unique())[i]\n",
    "        lst.append([feature,\n",
    "                    val,  # Value\n",
    "                    df[df[feature] == val].count()[feature],  # all\n",
    "                    df[(df[feature] == val) & (df[target] == 0)].count()[feature],  # good rate\n",
    "                    df[(df[feature] == val) & (df[target] == 1)].count()[feature]])  # bad rate\n",
    "    data = pd.DataFrame(lst, columns=['Variable', 'Value', 'All', 'Good', 'Bad'])\n",
    "\n",
    "    data['Share'] = data['All'] / data['All'].sum()\n",
    "    data['Bad Rate'] = data['Bad'] / data['All']\n",
    "    data['Distribution Good'] = (data['All'] - data['Bad']) / (data['All'].sum() - data['Bad'].sum())\n",
    "    data['Distribution Bad'] = data['Bad'] / data['Bad'].sum()\n",
    "    data['WoE'] = np.log(data['Distribution Good'] / data['Distribution Bad'])\n",
    "\n",
    "    data = data.replace({'WoE': {np.inf: 0, -np.inf: 0}})\n",
    "\n",
    "    data['IV'] = data['WoE'] * (data['Distribution Good'] - data['Distribution Bad'])\n",
    "\n",
    "    data = data.sort_values(by=['Variable', 'Value'], ascending=[True, True])\n",
    "    data.index = range(len(data.index))\n",
    "\n",
    "    if pr:\n",
    "        print(data)\n",
    "        print(\"IV = \", data['IV'].sum())\n",
    "\n",
    "    iv = data['IV'].sum()\n",
    "\n",
    "    return iv, data\n",
    "\n",
    "\n",
    "df = pd.read_csv('../DataSets/001data.csv', encoding='gbk')\n",
    "column_headers = list(df.columns.values)\n",
    "# print(column_headers)\n",
    "del column_headers[11]\n",
    "for x in column_headers:\n",
    "    IV_1, data = calc_iv(df, x, 'status')\n",
    "    print('{}： {}'.format(x, IV_1))\n",
    "\n",
    "# for example:\n",
    "# calc_iv(df, 'NET_TM', 'overdue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
